{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c0d0c9-ba31-4494-b7ab-af4e264721e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "from  matplotlib.colors import LinearSegmentedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466eaef5-1cc2-4546-a7b9-c7672ed43d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = LinearSegmentedColormap.from_list('w',[\"w\", \"w\"], N=256)\n",
    "\n",
    "ACTIONS = {\n",
    "    0: [1, 0],   # north\n",
    "    1: [-1, 0],  # south\n",
    "    2: [0, -1],  # west\n",
    "    3: [0, 1],   # east\n",
    "}\n",
    "\n",
    "class GridWorld:\n",
    "    def __init__(self, size=4):\n",
    "        \"\"\"\n",
    "        A gridworld environment with absorbing states at [0, 0] and [size - 1, size - 1].\n",
    "        Args:\n",
    "            size (int): the dimension of the grid in each direction\n",
    "            cell_reward (float): the reward return after extiting any non absorbing state\n",
    "        \"\"\"\n",
    "        self.reset()\n",
    "        return\n",
    "\n",
    "    def reset(self):\n",
    "        self.state_value = np.zeros((size, size))\n",
    "        return\n",
    "\n",
    "    def step(self, state, action):\n",
    "        # is terminal state?\n",
    "        size = len(self.state_value) - 1\n",
    "        if (state == (0, 0)) or (state == (size, size)):\n",
    "            return state, 0\n",
    "            \n",
    "        s_1 = (state[0] + action[0], state[1] + action[1])\n",
    "        reward = -1\n",
    "        # out of bounds north-south\n",
    "        if s_1[0] < 0 or s_1[0] >= len(self.state_value):\n",
    "            s_1 = state\n",
    "        # out of bounds east-west\n",
    "        elif s_1[1] < 0 or s_1[1] >= len(self.state_value):\n",
    "            s_1 = state\n",
    "\n",
    "        return s_1, reward\n",
    "\n",
    "    def render(self, title=None):\n",
    "        \"\"\"\n",
    "        Displays the current value table of mini gridworld environment\n",
    "        \"\"\"\n",
    "        size = len(self.state_value) if len(self.state_value) < 20 else 20\n",
    "        fig, ax = plt.subplots(figsize=(size, size))\n",
    "        if title is not None:\n",
    "            ax.set_title(title)\n",
    "        ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=2)\n",
    "        return sn.heatmap(self.state_value, annot=True, fmt=\".1f\", cmap=W, linewidths=1, linecolor=\"black\", cbar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44412c0a-7723-4147-b043-d9bc18bd1adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bellman_expectation(self, state, probs, discount):\n",
    "        \"\"\"\n",
    "        Makes a one step lookahead and applies the bellman expectation equation to the state self.state_value[state]\n",
    "        Args:\n",
    "            state (Tuple[int, int]): the x, y indices that define the address on the value table\n",
    "            probs (List[float]): transition probabilities for each action\n",
    "            in_place (bool): if False, the value table is updated after all the new values have been calculated.\n",
    "                             if True the state [i, j] will new already new values for the states [< i, < j]\n",
    "        Returns:\n",
    "            (numpy.ndarrray): the new value for the specified state\n",
    "        \"\"\"\n",
    "        # absorbing state\n",
    "        value = 0\n",
    "        for c, action in ACTIONS.items():\n",
    "            s_1, reward = self.step(state, action)\n",
    "            value += probs[c] * (reward + discount * self.state_value[s_1])\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89ff42-dc4d-484a-be9e-f1531d9016dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy_evaluation(env, policy=None, steps=1, discount=1., in_place=False):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        policy (numpy.array): a numpy 3-D numpy array, where the first two dimensions identify a state and the third dimension identifies the actions.\n",
    "                              The array stores the probability of taking each action.\n",
    "        steps (int): the number of iterations of the algorithm\n",
    "        discount (float): discount factor for the bellman equations\n",
    "        in_place (bool): if False, the value table is updated after all the new values have been calculated.\n",
    "             if True the state [i, j] will new already new values for the states [< i, < j]\n",
    "    \"\"\"\n",
    "    if policy is None:\n",
    "        # uniform random policy\n",
    "        policy = np.ones((*env.state_value.shape, len(ACTIONS))) * 0.25\n",
    "\n",
    "    for k in range(steps):\n",
    "        # cache old values if not in place\n",
    "        values = env.state_value if in_place else np.empty_like(env.state_value)\n",
    "        for i in range(len(env.state_value)):\n",
    "            for j in range(len(env.state_value[i])):\n",
    "                # apply bellman expectation equation to each state\n",
    "                state = (i, j)\n",
    "                value = env.bellman_expectation(state, policy[i, j], discount)\n",
    "                values[i, j] = value * discount\n",
    "        # set the new value table\n",
    "        env.state_value = values\n",
    "    return env.state_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc51119-8a92-47d4-8b88-44ffaa989a74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
